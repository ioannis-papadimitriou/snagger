{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the dataset\n",
    "dataset = pd.read_csv('Churn_Modelling.csv')\n",
    "X = dataset.iloc[:, 3:13].values\n",
    "y = dataset.iloc[:, 13].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/reaper/anaconda3/envs/dl/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/reaper/anaconda3/envs/dl/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
      "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Encoding categorical data\n",
    "#print(X)\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "labelencoder_X_1 = LabelEncoder()\n",
    "X[:, 1] = labelencoder_X_1.fit_transform(X[:, 1])\n",
    "#print(X)\n",
    "labelencoder_X_2 = LabelEncoder()\n",
    "X[:, 2] = labelencoder_X_2.fit_transform(X[:, 2])\n",
    "#print(X)\n",
    "onehotencoder = OneHotEncoder(categorical_features = [1])\n",
    "X = onehotencoder.fit_transform(X).toarray()\n",
    "#print(X)\n",
    "X = X[:, 1:] #get rid of one column to avoid dummy variable trap\n",
    "#print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling (compulsory for ANN)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/reaper/anaconda3/envs/dl/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/reaper/anaconda3/envs/dl/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/reaper/anaconda3/envs/dl/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/reaper/anaconda3/envs/dl/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/reaper/anaconda3/envs/dl/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/reaper/anaconda3/envs/dl/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/reaper/anaconda3/envs/dl/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/reaper/anaconda3/envs/dl/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/reaper/anaconda3/envs/dl/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/reaper/anaconda3/envs/dl/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/reaper/anaconda3/envs/dl/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/reaper/anaconda3/envs/dl/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# Part 2 - Now let's make the ANN!\n",
    "\n",
    "# Importing the Keras libraries and packages\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/reaper/anaconda3/envs/dl/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/reaper/anaconda3/envs/dl/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/reaper/anaconda3/envs/dl/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/reaper/anaconda3/envs/dl/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/reaper/anaconda3/envs/dl/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/reaper/anaconda3/envs/dl/lib/python3.7/site-packages/ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=11, units=10, kernel_initializer=\"uniform\")`\n",
      "  \"\"\"\n",
      "/home/reaper/anaconda3/envs/dl/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=8, kernel_initializer=\"uniform\")`\n",
      "  if __name__ == '__main__':\n",
      "/home/reaper/anaconda3/envs/dl/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=6, kernel_initializer=\"uniform\")`\n",
      "  del sys.path[0]\n",
      "/home/reaper/anaconda3/envs/dl/lib/python3.7/site-packages/ipykernel_launcher.py:16: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\")`\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/reaper/anaconda3/envs/dl/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/reaper/anaconda3/envs/dl/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "Epoch 1/100\n",
      "8000/8000 [==============================] - 9s 1ms/step - loss: 0.4735 - acc: 0.7954\n",
      "Epoch 2/100\n",
      "8000/8000 [==============================] - 11s 1ms/step - loss: 0.4268 - acc: 0.7960\n",
      "Epoch 3/100\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 0.4213 - acc: 0.8085\n",
      "Epoch 4/100\n",
      "8000/8000 [==============================] - 9s 1ms/step - loss: 0.4178 - acc: 0.8267\n",
      "Epoch 5/100\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 0.4156 - acc: 0.8292\n",
      "Epoch 6/100\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 0.4134 - acc: 0.8305\n",
      "Epoch 7/100\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 0.4121 - acc: 0.8311\n",
      "Epoch 8/100\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 0.4121 - acc: 0.8327\n",
      "Epoch 9/100\n",
      "8000/8000 [==============================] - 9s 1ms/step - loss: 0.4104 - acc: 0.8330\n",
      "Epoch 10/100\n",
      "8000/8000 [==============================] - 12s 1ms/step - loss: 0.4092 - acc: 0.8332\n",
      "Epoch 11/100\n",
      "8000/8000 [==============================] - 9s 1ms/step - loss: 0.4085 - acc: 0.8342\n",
      "Epoch 12/100\n",
      "8000/8000 [==============================] - 9s 1ms/step - loss: 0.4078 - acc: 0.8354\n",
      "Epoch 13/100\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 0.4073 - acc: 0.8340\n",
      "Epoch 14/100\n",
      "8000/8000 [==============================] - 7s 846us/step - loss: 0.4062 - acc: 0.8342\n",
      "Epoch 15/100\n",
      "8000/8000 [==============================] - 6s 757us/step - loss: 0.4060 - acc: 0.8360\n",
      "Epoch 16/100\n",
      "8000/8000 [==============================] - 3s 412us/step - loss: 0.4056 - acc: 0.8337\n",
      "Epoch 17/100\n",
      "8000/8000 [==============================] - 3s 437us/step - loss: 0.4054 - acc: 0.8342\n",
      "Epoch 18/100\n",
      "8000/8000 [==============================] - 4s 449us/step - loss: 0.4048 - acc: 0.8349\n",
      "Epoch 19/100\n",
      "8000/8000 [==============================] - 4s 448us/step - loss: 0.4041 - acc: 0.8336\n",
      "Epoch 20/100\n",
      "8000/8000 [==============================] - 4s 485us/step - loss: 0.4043 - acc: 0.8354\n",
      "Epoch 21/100\n",
      "8000/8000 [==============================] - 3s 431us/step - loss: 0.4041 - acc: 0.8344\n",
      "Epoch 22/100\n",
      "8000/8000 [==============================] - 3s 431us/step - loss: 0.4037 - acc: 0.8346\n",
      "Epoch 23/100\n",
      "8000/8000 [==============================] - 3s 421us/step - loss: 0.4040 - acc: 0.8354\n",
      "Epoch 24/100\n",
      "8000/8000 [==============================] - 5s 613us/step - loss: 0.4034 - acc: 0.8342\n",
      "Epoch 25/100\n",
      "8000/8000 [==============================] - 7s 872us/step - loss: 0.4032 - acc: 0.8334\n",
      "Epoch 26/100\n",
      "8000/8000 [==============================] - 11s 1ms/step - loss: 0.4030 - acc: 0.8336\n",
      "Epoch 27/100\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 0.4024 - acc: 0.8344\n",
      "Epoch 28/100\n",
      "8000/8000 [==============================] - 11s 1ms/step - loss: 0.4029 - acc: 0.8347\n",
      "Epoch 29/100\n",
      "8000/8000 [==============================] - 12s 1ms/step - loss: 0.4028 - acc: 0.8345\n",
      "Epoch 30/100\n",
      "8000/8000 [==============================] - 12s 1ms/step - loss: 0.4023 - acc: 0.8352\n",
      "Epoch 31/100\n",
      "8000/8000 [==============================] - 7s 886us/step - loss: 0.4020 - acc: 0.8352\n",
      "Epoch 32/100\n",
      "8000/8000 [==============================] - 6s 694us/step - loss: 0.4022 - acc: 0.8351\n",
      "Epoch 33/100\n",
      "8000/8000 [==============================] - 8s 989us/step - loss: 0.4024 - acc: 0.8350\n",
      "Epoch 34/100\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 0.4021 - acc: 0.8355\n",
      "Epoch 35/100\n",
      "8000/8000 [==============================] - 9s 1ms/step - loss: 0.4011 - acc: 0.8346\n",
      "Epoch 36/100\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 0.4017 - acc: 0.8366\n",
      "Epoch 37/100\n",
      "8000/8000 [==============================] - 11s 1ms/step - loss: 0.4014 - acc: 0.8344\n",
      "Epoch 38/100\n",
      "8000/8000 [==============================] - 12s 2ms/step - loss: 0.4013 - acc: 0.8359\n",
      "Epoch 39/100\n",
      "8000/8000 [==============================] - 7s 919us/step - loss: 0.4008 - acc: 0.8327\n",
      "Epoch 40/100\n",
      "8000/8000 [==============================] - 6s 696us/step - loss: 0.4011 - acc: 0.8357\n",
      "Epoch 41/100\n",
      "8000/8000 [==============================] - 5s 642us/step - loss: 0.4006 - acc: 0.8342\n",
      "Epoch 42/100\n",
      "8000/8000 [==============================] - 5s 621us/step - loss: 0.4005 - acc: 0.8347\n",
      "Epoch 43/100\n",
      "8000/8000 [==============================] - 5s 665us/step - loss: 0.4008 - acc: 0.8352\n",
      "Epoch 44/100\n",
      "8000/8000 [==============================] - 4s 560us/step - loss: 0.4004 - acc: 0.8347\n",
      "Epoch 45/100\n",
      "8000/8000 [==============================] - 8s 1ms/step - loss: 0.4000 - acc: 0.8357\n",
      "Epoch 46/100\n",
      "8000/8000 [==============================] - 9s 1ms/step - loss: 0.3997 - acc: 0.8351\n",
      "Epoch 47/100\n",
      "8000/8000 [==============================] - 11s 1ms/step - loss: 0.3997 - acc: 0.8347\n",
      "Epoch 48/100\n",
      "8000/8000 [==============================] - 11s 1ms/step - loss: 0.3993 - acc: 0.8362\n",
      "Epoch 49/100\n",
      "8000/8000 [==============================] - 7s 880us/step - loss: 0.3993 - acc: 0.8364\n",
      "Epoch 50/100\n",
      "8000/8000 [==============================] - 4s 521us/step - loss: 0.3994 - acc: 0.8330\n",
      "Epoch 51/100\n",
      "8000/8000 [==============================] - 4s 448us/step - loss: 0.3990 - acc: 0.8356\n",
      "Epoch 52/100\n",
      "8000/8000 [==============================] - 4s 473us/step - loss: 0.3986 - acc: 0.8335\n",
      "Epoch 53/100\n",
      "8000/8000 [==============================] - 4s 457us/step - loss: 0.3978 - acc: 0.8351\n",
      "Epoch 54/100\n",
      "8000/8000 [==============================] - 5s 598us/step - loss: 0.3972 - acc: 0.8357\n",
      "Epoch 55/100\n",
      "8000/8000 [==============================] - 4s 547us/step - loss: 0.3958 - acc: 0.8359\n",
      "Epoch 56/100\n",
      "8000/8000 [==============================] - 5s 597us/step - loss: 0.3928 - acc: 0.8366\n",
      "Epoch 57/100\n",
      "8000/8000 [==============================] - 4s 536us/step - loss: 0.3876 - acc: 0.8395\n",
      "Epoch 58/100\n",
      "8000/8000 [==============================] - 4s 535us/step - loss: 0.3807 - acc: 0.8405\n",
      "Epoch 59/100\n",
      "8000/8000 [==============================] - 6s 718us/step - loss: 0.3736 - acc: 0.8474\n",
      "Epoch 60/100\n",
      "8000/8000 [==============================] - 12s 1ms/step - loss: 0.3668 - acc: 0.8510\n",
      "Epoch 61/100\n",
      "8000/8000 [==============================] - 12s 1ms/step - loss: 0.3578 - acc: 0.8544\n",
      "Epoch 62/100\n",
      "8000/8000 [==============================] - 7s 840us/step - loss: 0.3503 - acc: 0.8559\n",
      "Epoch 63/100\n",
      "8000/8000 [==============================] - 6s 762us/step - loss: 0.3480 - acc: 0.8581\n",
      "Epoch 64/100\n",
      "8000/8000 [==============================] - 6s 793us/step - loss: 0.3461 - acc: 0.8610\n",
      "Epoch 65/100\n",
      "8000/8000 [==============================] - 12s 2ms/step - loss: 0.3458 - acc: 0.8607\n",
      "Epoch 66/100\n",
      "8000/8000 [==============================] - 11s 1ms/step - loss: 0.3446 - acc: 0.8617\n",
      "Epoch 67/100\n",
      "8000/8000 [==============================] - 7s 896us/step - loss: 0.3440 - acc: 0.8622\n",
      "Epoch 68/100\n",
      "8000/8000 [==============================] - 6s 708us/step - loss: 0.3430 - acc: 0.8619\n",
      "Epoch 69/100\n",
      "8000/8000 [==============================] - 14s 2ms/step - loss: 0.3428 - acc: 0.8624\n",
      "Epoch 70/100\n",
      "8000/8000 [==============================] - 15s 2ms/step - loss: 0.3430 - acc: 0.8631\n",
      "Epoch 71/100\n",
      "8000/8000 [==============================] - 12s 2ms/step - loss: 0.3429 - acc: 0.8625\n",
      "Epoch 72/100\n",
      "8000/8000 [==============================] - 4s 550us/step - loss: 0.3423 - acc: 0.8627\n",
      "Epoch 73/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.3409 - acc: 0.8632\n",
      "Epoch 74/100\n",
      "8000/8000 [==============================] - 3s 430us/step - loss: 0.3409 - acc: 0.8636\n",
      "Epoch 75/100\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 0.3415 - acc: 0.8636: 3s - loss:\n",
      "Epoch 76/100\n",
      "8000/8000 [==============================] - 3s 422us/step - loss: 0.3402 - acc: 0.8651\n",
      "Epoch 77/100\n",
      "8000/8000 [==============================] - 8s 1ms/step - loss: 0.3402 - acc: 0.8622\n",
      "Epoch 78/100\n",
      "8000/8000 [==============================] - 7s 814us/step - loss: 0.3395 - acc: 0.8627\n",
      "Epoch 79/100\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 0.3387 - acc: 0.8629\n",
      "Epoch 80/100\n",
      "8000/8000 [==============================] - 15s 2ms/step - loss: 0.3390 - acc: 0.8634\n",
      "Epoch 81/100\n",
      "8000/8000 [==============================] - 15s 2ms/step - loss: 0.3373 - acc: 0.8627\n",
      "Epoch 82/100\n",
      "8000/8000 [==============================] - 6s 781us/step - loss: 0.3374 - acc: 0.8636\n",
      "Epoch 83/100\n",
      "8000/8000 [==============================] - 4s 446us/step - loss: 0.3366 - acc: 0.8637\n",
      "Epoch 84/100\n",
      "8000/8000 [==============================] - 4s 535us/step - loss: 0.3366 - acc: 0.8636\n",
      "Epoch 85/100\n",
      "8000/8000 [==============================] - 4s 535us/step - loss: 0.3364 - acc: 0.8660\n",
      "Epoch 86/100\n",
      "8000/8000 [==============================] - 7s 882us/step - loss: 0.3363 - acc: 0.8632\n",
      "Epoch 87/100\n",
      "8000/8000 [==============================] - 5s 684us/step - loss: 0.3357 - acc: 0.8646\n",
      "Epoch 88/100\n",
      "8000/8000 [==============================] - 4s 527us/step - loss: 0.3358 - acc: 0.8624\n",
      "Epoch 89/100\n",
      "8000/8000 [==============================] - 15s 2ms/step - loss: 0.3363 - acc: 0.8657\n",
      "Epoch 90/100\n",
      "8000/8000 [==============================] - 15s 2ms/step - loss: 0.3358 - acc: 0.8632\n",
      "Epoch 91/100\n",
      "8000/8000 [==============================] - 7s 903us/step - loss: 0.3362 - acc: 0.8640\n",
      "Epoch 92/100\n",
      "8000/8000 [==============================] - 4s 530us/step - loss: 0.3361 - acc: 0.8659\n",
      "Epoch 93/100\n",
      "8000/8000 [==============================] - 9s 1ms/step - loss: 0.3350 - acc: 0.8661\n",
      "Epoch 94/100\n",
      "8000/8000 [==============================] - 8s 1ms/step - loss: 0.3356 - acc: 0.8640\n",
      "Epoch 95/100\n",
      "8000/8000 [==============================] - 12s 1ms/step - loss: 0.3355 - acc: 0.8651\n",
      "Epoch 96/100\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 0.3353 - acc: 0.8610\n",
      "Epoch 97/100\n",
      "8000/8000 [==============================] - 4s 517us/step - loss: 0.3351 - acc: 0.8642\n",
      "Epoch 98/100\n",
      "8000/8000 [==============================] - 7s 888us/step - loss: 0.3355 - acc: 0.8640\n",
      "Epoch 99/100\n",
      "8000/8000 [==============================] - 7s 843us/step - loss: 0.3345 - acc: 0.8649\n",
      "Epoch 100/100\n",
      "8000/8000 [==============================] - 6s 700us/step - loss: 0.3346 - acc: 0.8634\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2e6bdf5350>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialising the ANN\n",
    "classifier = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "classifier.add(Dense(output_dim = 10, init = 'uniform', activation = 'relu', input_dim = 11))\n",
    "# output_nod number of nodes of the hidden layer - tip: average of the number of nodes in the input layer and the output layer\n",
    "\n",
    "# Adding the second hidden layer\n",
    "classifier.add(Dense(output_dim = 8, init = 'uniform', activation = 'relu'))\n",
    "# now input_dim is not needed\n",
    "\n",
    "# Adding the third hidden layer\n",
    "classifier.add(Dense(output_dim = 6, init = 'uniform', activation = 'relu'))\n",
    "\n",
    "# Adding the output layer\n",
    "classifier.add(Dense(output_dim = 1, init = 'uniform', activation = 'sigmoid'))\n",
    "\n",
    "# Compiling the ANN\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# Fitting the ANN to the Training set\n",
    "classifier.fit(X_train, y_train, batch_size = 10, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 3 - Making the predictions and evaluating the model\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1519   76]\n",
      " [ 194  211]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1, 'Confusion Matrix')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Making the Confusion Matrix\n",
    "import seaborn as sn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "df_cm = pd.DataFrame(cm, range(2), range(2))\n",
    "ax= plt.subplot()\n",
    "sn.heatmap(df_cm, annot=True, ax = ax); #annot=True to annotate cells\n",
    "print(cm)\n",
    "# labels, title and ticks\n",
    "ax.set_xlabel('Predicted labels')\n",
    "ax.set_ylabel('True labels')\n",
    "ax.set_title('Confusion Matrix')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
